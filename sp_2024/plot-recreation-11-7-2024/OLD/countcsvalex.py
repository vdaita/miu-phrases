# -*- coding: utf-8 -*-
"""countCsvAlex.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/189yy4jCplrdq-KP-rgiaBX0b7bubbOJc
"""

import re
import pandas as pd
from multiprocess import Pool
from functools import partial
import multiprocess as mp
import matplotlib.pyplot as plt

keywords = [
    "made in america", "made in u.s.", "made in us", # made in usa and made in us overlap
    "american made", "usa made", "u.s. made", "us made"
    "buy american", "buy usa", "buy america",
    "support america", "support usa", "support u.s.",
    "patriot",
    "choose american", "choose usa", "choose u.s.", "choose america",
    "national pride",
    "usa based", "america based", "american based", "us based", "u.s. based",
    "usa produced", "america produced", "american produced", "us produced", "u.s. produced",
    "usa manufactured", "america manufactured", "american manufactured", "us manufactured", "u.s. manufactured",
    "american worker", "american job",
    "veteran owned", "veteran founded", "founded by veteran",
    "handcrafted in america", "handcrafted in usa", "handcrafted in u.s.", "handcrafted in us",
    "crafted in america", "crafted in u.s.", "crafted in us", # removed "crafted in the usa" due to overlap with crafted in the US
    "america heritage", "america tradition", "america value",
    "icon of america", "icon of usa", "icon of u.s.",
    "america manufactur", "u.s. manufactur"
]

df = pd.read_csv("buy_usa_second_round_with_additional_firms.csv")
df = pd.read_csv("about_us_second_round_with_additional_firms.csv")
df = pd.read_csv("company_website_second_round_with_additional_firms.csv")

def filter_columns(df):
    pattern = r"^\d{4}-\d{2}$"  # Regex to match the YYYY-MM format
    # Keep 'std_name' and any other column that matches the date format
    filtered_columns = ['std_name'] + [col for col in df.columns if re.match(pattern, col)]
    return df[filtered_columns]

df = filter_columns(df)
df = df.drop_duplicates(subset='std_name', keep='first').reset_index(drop=True)
df = df.sort_values(by='std_name').reset_index(drop=True)
df = df.drop(columns=['std_name'])
columns = list(df.columns)

df.sample(50)

def count_keywords_in_cell(cell, keywords):
    return sum(1 if keyword.lower() in str(cell).lower() else 0 for keyword in keywords)

def calculate_total_counts(df, columns, keywords):
    total_counts_df = pd.DataFrame(index=df.index, columns=columns, dtype=int).fillna(0)

    for index, row in df.iterrows():
        previous_count = 0  # Initialize the previous count
        for col_idx, col in enumerate(reversed(columns)):
            cell_value = row[col]
            current_count = count_keywords_in_cell(cell_value, keywords)

            # If the current count is zero and the previous count is greater than zero, use the previous count
            if current_count == 0 and previous_count > 0:
                total_counts_df.at[index, columns[len(columns) - 1 - col_idx]] = previous_count
            else:
                total_counts_df.at[index, columns[len(columns) - 1 - col_idx]] = current_count
                previous_count = current_count  # Update previous count

    return total_counts_df

total_counts_df = calculate_total_counts(df, columns, keywords)

document_counts = [0] * len(columns) # Initialize a list to hold the count of documents for each year.

for row in df.itertuples(index=False):# Iterate over each row in the DataFrame.
    previous_count = 0 # Initialize the previous count to 0 for the first iteration.

    for idx in reversed(range(len(columns))):    # Iterate over the columns in reverse order to update the document count.
        value = row[idx] # Access the value using the appropriate index for itertuples() output.

        # Check if the current cell has a document (non-NaN and not an empty string).
        if pd.isna(value) or isinstance(value, int):
            document_counts[idx] += previous_count # If there's a document, increment the count for the year and set the previous count to 1.
        else:
            document_counts[idx] += 1 # If there's no document, add the previous year's count to this year's count.
            previous_count = 1 # We have found a document so previous should never be 0



total_documents = sum(document_counts)
document_count_sum = total_documents
# Print the total number of documents.
print(total_documents)

# This number is less than other because the index column was included in previous calculations

def count_term_existence(df, columns, total_counts_df, keyword):
    import pandas as pd
    print(f"Processing keyword: {keyword}")
    term_existence = [0] * len(columns)

    for index, row in df.iterrows():
        previous_total_count = 0  # Initialize the total count for all keywords in the previous cell
        for col_idx, col in enumerate(reversed(columns)):
            cell_value = row[col]
            current_total_count = total_counts_df.at[index, col]

            if current_total_count == 0 and previous_total_count > 0:
                # If total count drops to 0 but was higher before, carry over the previous value
                term_existence[len(columns) - 1 - col_idx] += 1
            elif pd.isna(cell_value) or isinstance(cell_value, int):
                term_existence[len(columns) - 1 - col_idx] += 0
            else:
                if keyword in cell_value.lower():
                    term_existence[len(columns) - 1 - col_idx] += 1
                else:
                    term_existence[len(columns) - 1 - col_idx] += 0

            if current_total_count == 0 and previous_total_count > 0:
                previous_total_count = previous_total_count
            else:
                previous_total_count = current_total_count  # Update the total count for the next iteration

    return {keyword: sum(term_existence)}

count_term_existence(df, columns, total_counts_df, 'made in america')

func = partial(count_term_existence, df, columns, total_counts_df)

# Initialize multiprocessing Pool
with Pool(processes=4) as pool:
    # Map the function across the keywords
    results = pool.map(func, keywords)

# Combine the results
term_count = {}
for result in results:
    term_count.update(result)

print(term_count)

# keyword_count = row[column].lower().count(keyword) # This is the term frequency within this document
                # value = (keyword_count * idf / len(row[column]))*100 # This is the formula

                # keyword_count = row[column].lower().count(keyword) # This is the term frequency within this document (for not using TF-IDF)
                # value = keyword_count # No changes to the value here! (for not using TF-IDF)

                # idf = math.log(1 + (document_count_sum/term_existence)) # This is the IDF formula
                # keyword_count = row[column].lower().count(keyword) # This is the term frequency within this document
                # value = (keyword_count * idf / len(row[column]))*100 # This is the formula

                # keyword_count = row[column].lower().count(keyword) # This is the term frequency within this document (for not using TF-IDF)
                # value = keyword_count # No changes to the value here! (for not using TF-IDF)

def generate_final_value_by_year(df, total_counts_df, columns, document_count_sum, data):
    import math
    import pandas as pd  # Ensure pandas is imported in the function's scope

    def count_keyword_in_cell(cell, keyword):
        return 1 if keyword.lower() in str(cell).lower() else 0

    def count_total_keywords(cell, keywords):
        return sum(count_keyword_in_cell(cell, kw) for kw in keywords)
    keyword, term_existence = data

    print("Processing keyword: ", keyword)
    term_existence_full = [0] * len(columns)

    if term_existence == 0: # Skip over if this term wasn't counted in any of the years
        return {keyword: term_existence_full}

    for index, row in df.iterrows():
        previous_value = 0
        previous_total_count = 0
        for col_idx, col in enumerate(reversed(columns)):
            cell_value = row[col]
            current_total_count = total_counts_df.at[index, col]

            if current_total_count == 0 and previous_total_count > 0:
                # If total count drops to 0 but was higher before, carry over the previous value
                term_existence_full[len(columns) - 1 - col_idx] += previous_value
            elif pd.isna(cell_value) or isinstance(cell_value, int):
                term_existence_full[len(columns) - 1 - col_idx] += 0
                previous_value = 0
            else:
                # if keyword in cell_value.lower():
                #     term_existence[len(columns) - 1 - col_idx] += 1
                # else:
                #     term_existence[len(columns) - 1 - col_idx] += 0


                idf = math.log(1 + (document_count_sum/term_existence)) # This is the IDF formula
                keyword_count = row[col].lower().count(keyword) # This is the term frequency within this document
                value = (keyword_count * idf / len(row[col]))*100 # This is the formula

                # keyword_count = row[col].lower().count(keyword) # This is the term frequency within this document (for not using TF-IDF)
                # value = keyword_count # No changes to the value here! (for not using TF-IDF)

                term_existence_full[len(columns) - 1 - col_idx] += value
                previous_value = value

            if current_total_count == 0 and previous_total_count > 0:
                previous_total_count = previous_total_count
            else:
                previous_total_count = current_total_count  # Update the total count for the next iteration


    return {keyword: term_existence_full}

# Run this over all of the different keywords

func = partial(generate_final_value_by_year, df, total_counts_df, columns, document_count_sum)

# Use multiprocessing to map the keywords to the function
pool = mp.Pool(processes=6)
results = pool.map(func, ((keyword, term_count[keyword]) for keyword in keywords))

# Combine the results
tf_idf_total = {}
for result in results:
    tf_idf_total.update(result)

year_sums = [0] * len(columns)
for keyword in keywords: # Going through all of the keywords
    if type(tf_idf_total[keyword]) == int: # This is a redundant invalid check
        continue
    for column in range(len(columns)): # Go through all of the years
        year_sums[column] += tf_idf_total[keyword][column] # Adding up all the sums per year

for column in range(len(columns)):
    # print(document_count[column])
    try:
        year_sums[column] /= document_counts[column]
        # year_sums[column] /= 1
    except:
        try:
            year_sums[column] /= document_counts[column+1]
            # year_sums[column] /= 1
        except:
            year_sums[column] /= 1
print(year_sums[:10])

columns_plot = pd.to_datetime(df.columns, errors='coerce', infer_datetime_format=True)
columns_plot = columns_plot.dropna()

# Ensure year_sums has the same length as columns after filtering NaT
# Adjust year_sums accordingly if necessary

print(len(columns_plot), columns_plot[:3])

fig, ax = plt.subplots(figsize=(8,6))
ax.plot(columns_plot, list(year_sums))  # Plotting it!

plt.show()  # Display the plot

year_sums_buy_usa_tfidf = year_sums # RAN TODAY

year_sums_buy_usa_no_tfidf = year_sums # RAN TODAY

year_sums_about_us_no_tfidf = year_sums # RAN TODAY

year_sums_about_us_tfidf = year_sums # RAN TODAY

year_sums_company_website_information_tfidf = year_sums # RAN TODAY

year_sums_company_website_information_no_tfidf = year_sums #RAN TODAY





# Update the combined TF-IDF calculation to include "Buy USA"
combined_tfidf = [sum(x) for x in zip(year_sums_buy_usa_tfidf, year_sums_about_us_tfidf, year_sums_company_website_information_tfidf)]

# Plot the TF-IDF values including "Buy USA"
plt.figure(figsize=(10, 6))
plt.plot(columns, year_sums_buy_usa_tfidf, label='Buy USA TF-IDF', linestyle='-', color='red')
plt.plot(columns, year_sums_about_us_tfidf, label='About Us TF-IDF', linestyle='-', color='orange')
plt.plot(columns, year_sums_company_website_information_tfidf, label='Company Website Information TF-IDF', linestyle='-', color='green')
plt.plot(columns, combined_tfidf, label='Combined TF-IDF', linestyle='-', color='blue')
plt.legend()
plt.title('TF-IDF Values Over Time')
plt.xlabel('Year')
plt.ylabel('TF-IDF Sum')
plt.show()

# Update the combined TF-IDF calculation to include all available data
combined_tfidf = [sum(x) for x in zip(year_sums_about_us_tfidf, year_sums_company_website_information_tfidf)]

# Plot the TF-IDF values
plt.figure(figsize=(10, 6))
plt.plot(columns, year_sums_about_us_tfidf, label='About Us TF-IDF', linestyle='-', color='orange')
plt.plot(columns, year_sums_company_website_information_tfidf, label='Company Website Information TF-IDF', linestyle='-', color='green')
plt.plot(columns, combined_tfidf, label='Combined TF-IDF', linestyle='-', color='blue')
plt.legend()
plt.title('TF-IDF Values Over Time')
plt.xlabel('Year')
plt.ylabel('TF-IDF Sum')
plt.show()

# Update the combined non-TF-IDF calculation to include all available data
combined_no_tfidf = [sum(x) for x in zip(year_sums_buy_usa_no_tfidf, year_sums_about_us_no_tfidf, year_sums_company_website_information_no_tfidf)]

# Plot the non-TF-IDF values, including the 'Buy USA No TF-IDF' series
plt.figure(figsize=(10, 6))
plt.plot(columns, year_sums_buy_usa_no_tfidf, label='Buy USA No TF-IDF', linestyle='-', color='red')
plt.plot(columns, year_sums_about_us_no_tfidf, label='About Us No TF-IDF', linestyle='-', color='orange')
plt.plot(columns, year_sums_company_website_information_no_tfidf, label='Company Website Information No TF-IDF', linestyle='-', color='green')
plt.plot(columns, combined_no_tfidf, label='Combined No TF-IDF', linestyle='-', color='blue')
plt.legend()
plt.title('Non-TF-IDF Values Over Time')
plt.xlabel('Year')
plt.ylabel('Sum')
plt.show()

columns_trimmed = columns[-min_length_no_tfidf:]

combined_no_tfidf = [sum(x) for x in zip(year_sums_buy_usa_no_tfidf_trimmed, year_sums_about_us_no_tfidf_trimmed, year_sums_company_website_information_no_tfidf_trimmed)]

# Plot the non-TF-IDF values, including the 'Buy USA No TF-IDF' series
plt.figure(figsize=(10, 6))
plt.plot(columns_trimmed, year_sums_buy_usa_no_tfidf_trimmed, label='Buy USA No TF-IDF', linestyle='-', color='red')
plt.plot(columns_trimmed, year_sums_about_us_no_tfidf_trimmed, label='About Us No TF-IDF', linestyle='-', color='orange')
plt.plot(columns_trimmed, year_sums_company_website_information_no_tfidf_trimmed, label='Company Website Information No TF-IDF', linestyle='-', color='green')
plt.plot(columns_trimmed, combined_no_tfidf, label='Combined No TF-IDF', linestyle='-', color='blue')
plt.legend()
plt.title('Non-TF-IDF Values Over Time')
plt.xlabel('Year')
plt.ylabel('Sum')
plt.show()

year_sums_company_website_information_no_tfidf_trimmed

columns = range(len(year_sums_company_website_information_no_tfidf_trimmed))

plt.figure(figsize=(10, 6))
plt.plot(columns, year_sums_company_website_information_no_tfidf_trimmed, linestyle='-', label='Data')  # Ensure lines are connected
plt.title('Data Visualization')
plt.xlabel('Index (or Time)')
plt.ylabel('Value')
plt.legend()
plt.show()

# Assuming year_sums_* variables are defined in the user's environment,
# we will save each one to a text file.

# Saving year_sums_buy_usa_tfidf to a text file
with open('/mnt/data/year_sums_buy_usa_tfidf.txt', 'w') as file:
    file.writelines(f"{value}\n" for value in year_sums_buy_usa_tfidf)

# Saving year_sums_buy_usa_no_tfidf to a text file
with open('/mnt/data/year_sums_buy_usa_no_tfidf.txt', 'w') as file:
    file.writelines(f"{value}\n" for value in year_sums_buy_usa_no_tfidf)

# Saving year_sums_about_us_tfidf to a text file
with open('/mnt/data/year_sums_about_us_tfidf.txt', 'w') as file:
    file.writelines(f"{value}\n" for value in year_sums_about_us_tfidf)

# Saving year_sums_about_us_no_tfidf to a text file
with open('/mnt/data/year_sums_about_us_no_tfidf.txt', 'w') as file:
    file.writelines(f"{value}\n" for value in year_sums_about_us_no_tfidf)

# Saving year_sums_company_website_information_tfidf to a text file
with open('/mnt/data/year_sums_company_website_information_tfidf.txt', 'w') as file:
    file.writelines(f"{value}\n" for value in year_sums_company_website_information_tfidf)

# Saving year_sums_company_website_information_no_tfidf to a text file
with open('/mnt/data/year_sums_company_website_information_no_tfidf.txt', 'w') as file:
    file.writelines(f"{value}\n" for value in year_sums_company_website_information_no_tfidf)

